{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative poems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting for un/rhyming poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from generative_formalism import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = {\n",
    "    'DO_rhyme': [\n",
    "        'Write a poem in ballad stanzas.',\n",
    "        \"Write an ryhmed poem in the style of Shakespeare's sonnets.\",\n",
    "        'Write a long poem that does rhyme.',\n",
    "        'Write a poem in the style of Emily Dickinson.',\n",
    "        'Write a poem in heroic couplets.',\n",
    "        'Write an rhyming poem.',\n",
    "        'Write a poem (with 20+ lines) that rhymes.',\n",
    "        'Write a poem that does rhyme.',\n",
    "        'Write a short poem that does rhyme.'\n",
    "    ],\n",
    "    \n",
    "    'do_NOT_rhyme': [\n",
    "        'Write a poem that does NOT rhyme.',\n",
    "        'Write a poem (with 20+ lines) that does NOT rhyme.',\n",
    "        'Write a long poem that does NOT rhyme.',\n",
    "        'Write a poem in the style of Walt Whitman.',\n",
    "        'Write a poem in free verse.',\n",
    "        'Write a poem in blank verse.',\n",
    "        'Write an unrhymed poem.',\n",
    "        'Write a short poem that does NOT rhyme.'],\n",
    "    'MAYBE_rhyme': [\n",
    "        'Write a poem (with 20+ lines).',\n",
    "        'Write a long poem.',\n",
    "        'Write a poem in groups of two lines.',\n",
    "        'Write a poem.',\n",
    "        'Write a poem in stanzas of 4 lines each.',\n",
    "        'Write a short poem.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "## generate prompt to type\n",
    "print('> Setting prompts from constant')\n",
    "PROMPT_TO_TYPE = {}\n",
    "for prompt_type, prompt_list in PROMPTS.items():\n",
    "    for prompt in prompt_list:\n",
    "        PROMPT_TO_TYPE[prompt] = prompt_type\n",
    "PROMPT_SET = set(PROMPT_TO_TYPE.keys())\n",
    "PROMPT_LIST = list(PROMPT_TO_TYPE.keys())\n",
    "\n",
    "print(f'  * {len(PROMPT_SET)} unique prompts')\n",
    "print(f'  * {len(PROMPTS)} prompt types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'claude-3-opus-20240229',\n",
    "    'claude-3-sonnet-20240229',\n",
    "    'deepseek/deepseek-chat',\n",
    "    'gemini-pro',\n",
    "    'gpt-3.5-turbo',\n",
    "    'gpt-4-turbo',\n",
    "    'ollama/llama3.1:70b',\n",
    "    'ollama/llama3.1:8b',\n",
    "    'ollama/olmo2',\n",
    "    'ollama/olmo2:13b'\n",
    "]\n",
    "\n",
    "print('> Setting models from constant')\n",
    "MODEL_TO_TYPE = {m:get_model_renamed(m) for m in MODEL_LIST}\n",
    "MODEL_TO_NAME = {m:get_model_cleaned(m) for m in MODEL_LIST}\n",
    "\n",
    "\n",
    "print(f'  * {len(MODEL_LIST)} models (counting parameter changes)')\n",
    "print(f'  * {len(set(MODEL_TO_NAME.values()))} model (discounting parameter changes)')\n",
    "print(f'  * {len(set(MODEL_TO_TYPE.values()))} model providers ({\", \".join(sorted(set(MODEL_TO_TYPE.values())))})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_prev_genai_promptings(path_pkl=PATH_RAW_PKL, path_json=PATH_RAW_JSON, prompts=PROMPTS, min_lines=10, max_lines=100, overwrite=False,):\n",
    "    printm('#### Collecting previous genai promptings')\n",
    "    valid_prompts = set(PROMPT_TO_TYPE.keys())\n",
    "    valid_models = set(MODEL_TO_TYPE.keys())\n",
    "\n",
    "    def get_df_poems():\n",
    "        print(f'  * Collecting from {path_pkl}')\n",
    "        if path_pkl and os.path.exists(path_pkl):\n",
    "            df_poems1 = pd.read_pickle(path_pkl).fillna('').query('prompt!=\"\"').rename(columns={'poem':'response'})\n",
    "            print(f'    * {len(df_poems1)} generated poems')\n",
    "        else:\n",
    "            df_poems1 = pd.DataFrame()\n",
    "        return df_poems1\n",
    "    \n",
    "    df1 = get_df_poems()\n",
    "\n",
    "    def get_jsonl_data():\n",
    "        import gzip\n",
    "\n",
    "        if path_json and os.path.exists(path_json):\n",
    "            print(f'  * Collecting from {path_json}')\n",
    "            newdata = []\n",
    "            with gzip.open(path_json, 'rt') as f:\n",
    "                ld = json.loads(f.read())\n",
    "                for d in ld:\n",
    "                    prompt = d['prompt']['user_prompt']\n",
    "                    model = d['prompt']['model']\n",
    "                    temp = d['prompt']['temperature']\n",
    "                    txt = d['response'].split('</think>')[-1].strip()\n",
    "                    newdata.append({\n",
    "                        'model':model,\n",
    "                        'temp':temp,\n",
    "                        'prompt':prompt,\n",
    "                        'response':txt,\n",
    "                    })\n",
    "            \n",
    "            print(f'    * {len(newdata)} generated poems')\n",
    "            df2=pd.DataFrame(newdata)\n",
    "            return df2\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    df2 = get_jsonl_data()\n",
    "    df_prompts = pd.concat([df1, df2])\n",
    "    df_prompts['txt'] = df_prompts.response.apply(clean_genai_poem)\n",
    "    df_prompts['num_lines'] = df_prompts.txt.apply(get_num_lines)\n",
    "    df_prompts['prompt_type'] = df_prompts.prompt.apply(lambda x: PROMPT_TO_TYPE.get(x, 'Unknown'))\n",
    "\n",
    "\n",
    "    print(f'  * Aggregated and filtered')\n",
    "    df_prompts = df_prompts[df_prompts.prompt.isin(valid_prompts)]\n",
    "    df_prompts = df_prompts[df_prompts.model.isin(valid_models)]\n",
    "    \n",
    "    print(f'    * {len(df_prompts):,} generated responses')\n",
    "    print(f'    * {df_prompts.response.nunique():,} unique responses')\n",
    "    print(f'    * {df_prompts.txt.nunique():,} unique poems')\n",
    "    print(f'    * {df_prompts.prompt.nunique():,} unique prompts')\n",
    "    print(f'    * {df_prompts.prompt_type.nunique():,} unique prompt types')\n",
    "\n",
    "\n",
    "\n",
    "    for ncol in ['temp','num_lines']:\n",
    "        df_prompts[ncol] = pd.to_numeric(df_prompts[ncol], errors='coerce')\n",
    "\n",
    "    cols = {\n",
    "        'prompt_type':'prompt_type',\n",
    "        'prompt':'prompt',\n",
    "        'model':'model',\n",
    "        'temp':'temp',\n",
    "        'txt':'txt',\n",
    "        'num_lines':'num_lines',\n",
    "    }\n",
    "\n",
    "    id_list = [get_id_hash_str(f'{model}__{temp:.4f}__{prompt}__{txt}') for model,temp,prompt,txt in zip(df_prompts.model,df_prompts.temp,df_prompts.prompt,df_prompts.txt)]\n",
    "    df_prompts['id_hash'] = [get_id_hash(id) for id in id_list]\n",
    "    df_prompts = df_prompts.sort_values('id_hash')\n",
    "    df_prompts['txt'] = df_prompts.txt.apply(clean_genai_poem)\n",
    "    df_prompts['num_lines'] = df_prompts.txt.apply(get_num_lines)\n",
    "    \n",
    "    df_prompts = df_prompts.query(f'num_lines >= {min_lines} and num_lines <= {max_lines}')\n",
    "    odf = df_prompts.drop_duplicates('id_hash').set_index('id_hash').sort_index()\n",
    "    odf=odf[cols.keys()].rename(columns=cols)\n",
    "    save_sample(odf, f'{PATH_DATA}/corpus_genai_promptings.csv.gz', overwrite=overwrite)\n",
    "    PATH_SAMPLE\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collect_prev_genai_promptings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add / remove models here\n",
    "# MODELS.remove('ollama/darkmoon/olmo:7B-instruct-q6-k')\n",
    "# MODELS.add('claude-4-sonnet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_MODEL = MODEL_LIST[0]\n",
    "DEMO_PROMPT = PROMPTS['do_NOT_rhyme'][0]\n",
    "\n",
    "printm(f'#### Demo for poem generation')\n",
    "print(f'  * Demo model: {DEMO_MODEL}')\n",
    "print(f'  * Demo prompt: {DEMO_PROMPT}')\n",
    "print(f'\\n>>>\\n')\n",
    "response = generate_text(\n",
    "    DEMO_MODEL,\n",
    "    DEMO_PROMPT,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "printm(f'##### Extracting poem from response:')\n",
    "printm(f\"```{clean_genai_poem(response)}```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_more_poems(n=1000, models=MODEL_LIST, prompts=PROMPT_LIST, temperatures=None, verbose=True):\n",
    "    iterr = tqdm(total=n, position=0)\n",
    "    bad_models = set()\n",
    "    for n in range(n):\n",
    "        if not models: break\n",
    "        if not prompts: break\n",
    "        model = random.choice(models)\n",
    "        prompt = random.choice(prompts)\n",
    "        temperature = round((random.choice(temperatures) if temperatures else random.uniform(0.0, 1.0)), 4)\n",
    "        iterr.set_description(f'>>> {model} ({temperature}): \"{prompt}\"')\n",
    "        try:\n",
    "            if verbose:\n",
    "                printm('----')\n",
    "            response = generate_text(\n",
    "                model,\n",
    "                prompt,\n",
    "                temperature=temperature,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            if verbose:\n",
    "                printm('----')\n",
    "        except Exception as e:\n",
    "            print(f'!!! Error on model: {model}')\n",
    "            models = [m for m in models if m != model]\n",
    "        iterr.update(1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_more_poems(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
