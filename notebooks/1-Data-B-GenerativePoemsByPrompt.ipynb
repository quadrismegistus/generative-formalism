{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "REPLICATE_LLM_DEMO = False\n",
    "REPLICATE_LLM_MANY = False\n",
    "N_TO_GENERATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from generative_formalism import *\n",
    "\n",
    "printm('# Generative poems: prompted for un/rhymed poems')\n",
    "printm('## Prompting models')\n",
    "printm('Edit `PROMPTS` and `MODEL_LIST` in `constants.py` to change prompts and models.')\n",
    "\n",
    "printm('### Current prompts ')\n",
    "describe_prompts()\n",
    "\n",
    "printm('### Current models')\n",
    "describe_models()\n",
    "\n",
    "# Do we have access to API keys?\n",
    "if REPLICATE_LLM_DEMO:\n",
    "    documentation(check_api_keys)\n",
    "    if check_api_keys():\n",
    "        demo_model, demo_prompt = get_demo_model_prompt()\n",
    "        # demo_model, demo_prompt = get_random_model_prompt()  # or a random one\n",
    "        print(f'* Demo model: {demo_model}')\n",
    "        print(f'* Demo prompt: {demo_prompt}\\n')\n",
    "\n",
    "        response_str = generate_rhyme_prompt_text(\n",
    "            model=demo_model,\n",
    "            prompt=demo_prompt,\n",
    "            verbose=True,\n",
    "            force=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T21:51:10.368970Z",
     "iopub.status.busy": "2025-09-15T21:51:10.368889Z",
     "iopub.status.idle": "2025-09-15T21:51:10.373029Z",
     "shell.execute_reply": "2025-09-15T21:51:10.372795Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of prompting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T21:51:10.374169Z",
     "iopub.status.busy": "2025-09-15T21:51:10.374101Z",
     "iopub.status.idle": "2025-09-15T21:51:11.760205Z",
     "shell.execute_reply": "2025-09-15T21:51:11.759932Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if REPLICATE_LLM_DEMO:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting with many models/prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentation(generate_more_poems_from_rhyme_prompts)\n",
    "\n",
    "# Run if enabled\n",
    "if REPLICATE_LLM_MANY and N_TO_GENERATE > 0:\n",
    "    \n",
    "    # Run\n",
    "    df_newdata = generate_more_poems_from_rhyme_prompts(\n",
    "        # df_sofar=pd.DataFrame(),\n",
    "        n=N_TO_GENERATE,\n",
    "        models = MODEL_LIST,\n",
    "        prompts = PROMPT_LIST,\n",
    "        temperatures=[DEFAULT_TEMPERATURE],\n",
    "        verbose=DEFAULT_VERBOSE,\n",
    "        force=True,\n",
    "        max_n_combo=25\n",
    "    )\n",
    "\n",
    "    # Display\n",
    "    display(df_newdata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting all promptings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docs\n",
    "printm(f'## Collecting all promptings')\n",
    "documentation(get_genai_rhyme_promptings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printm(f'### Data used in paper')\n",
    "\n",
    "df_genai_rhyme_promptings_as_in_paper = get_genai_rhyme_promptings(\n",
    "    as_in_paper=True,\n",
    "    display=False, \n",
    "    verbose=True\n",
    ")\n",
    "df_genai_rhyme_promptings_as_in_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data replicated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genai_rhyme_promptings_as_replicated = get_genai_rhyme_promptings(\n",
    "    as_in_paper=False,\n",
    "    as_replicated=True,\n",
    "    display=False, \n",
    "    verbose=True\n",
    ")\n",
    "df_genai_rhyme_promptings_as_replicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating paper + replicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together\n",
    "df_all_rhyme_promptings = get_genai_rhyme_promptings(\n",
    "    as_in_paper=True,\n",
    "    as_replicated=True,\n",
    "    display=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "describe_qual(df_all_rhyme_promptings.data_source)\n",
    "df_all_rhyme_promptings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
