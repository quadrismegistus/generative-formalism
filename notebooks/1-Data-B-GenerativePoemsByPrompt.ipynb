{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "REPLICATE_LLM_DEMO = True\n",
    "REPLICATE_LLM_MANY = False\n",
    "N_TO_GENERATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Generative poems: prompted for un/rhymed poems"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Prompting models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Edit `PROMPTS` and `MODEL_LIST` in `constants.py` to change prompts and models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Current prompts "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 23 unique prompts\n",
      "* 3 prompt types\n",
      "  * MAYBE_rhyme:\n",
      "    - Write a poem (with 20+ lines).\n",
      "    - Write a long poem.\n",
      "    - Write a poem in groups of two lines.\n",
      "    - Write a poem.\n",
      "    - Write a poem in stanzas of 4 lines each.\n",
      "    - Write a short poem.\n",
      "\n",
      "  * DO_rhyme:\n",
      "    - Write a poem in ballad stanzas.\n",
      "    - Write an ryhmed poem in the style of Shakespeare's sonnets.\n",
      "    - Write a long poem that does rhyme.\n",
      "    - Write a poem in the style of Emily Dickinson.\n",
      "    - Write a poem in heroic couplets.\n",
      "    - Write an rhyming poem.\n",
      "    - Write a poem (with 20+ lines) that rhymes.\n",
      "    - Write a poem that does rhyme.\n",
      "    - Write a short poem that does rhyme.\n",
      "\n",
      "  * do_NOT_rhyme:\n",
      "    - Write a poem that does NOT rhyme.\n",
      "    - Write a poem (with 20+ lines) that does NOT rhyme.\n",
      "    - Write a long poem that does NOT rhyme.\n",
      "    - Write a poem in the style of Walt Whitman.\n",
      "    - Write a poem in free verse.\n",
      "    - Write a poem in blank verse.\n",
      "    - Write an unrhymed poem.\n",
      "    - Write a short poem that does NOT rhyme.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Current models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 11 models (counting parameter changes)\n",
      "* 6 model types (ChatGPT, Claude, DeepSeek, Gemini, Llama, Olmo)\n",
      "  * Claude:\n",
      "    - claude-3-haiku-20240307\n",
      "    - claude-3-opus-20240229\n",
      "    - claude-3-sonnet-20240229\n",
      "  * Llama:\n",
      "    - ollama/llama3.1:70b\n",
      "    - ollama/llama3.1:8b\n",
      "  * Olmo:\n",
      "    - ollama/olmo2\n",
      "    - ollama/olmo2:13b\n",
      "  * DeepSeek:\n",
      "    - deepseek/deepseek-chat\n",
      "  * ChatGPT:\n",
      "    - gpt-3.5-turbo\n",
      "    - gpt-4-turbo\n",
      "  * Gemini:\n",
      "    - gemini-pro\n",
      "✓ Gemini API key\n",
      "✓ OpenAI API key\n",
      "✓ Anthropic API key\n",
      "✓ DeepSeek API key\n",
      "  ✗ claude-3-haiku-20240307\n",
      "  ✗ claude-3-opus-20240229\n",
      "  ✗ claude-3-sonnet-20240229\n",
      "  ✗ deepseek/deepseek-chat\n",
      "  ✗ gemini-pro\n",
      "  ✗ gpt-3.5-turbo\n",
      "  ✗ gpt-4-turbo\n",
      "  ✗ ollama/llama3.1:70b\n",
      "  ✗ ollama/llama3.1:8b\n",
      "  ✗ ollama/olmo2\n",
      "  ✗ ollama/olmo2:13b\n",
      "* Demo model: claude-3-haiku-20240307\n",
      "* Demo prompt: Write a poem that does NOT rhyme.\n",
      "\n",
      "* Generating text\n",
      "  * model: claude-3-haiku-20240307\n",
      "  * prompt: Write a poem that does NOT rhyme.\n",
      "  * temperature: 0.7\n",
      "  * force: True\n",
      "  * stash: PairtreeHashStash(~/github/generative-formalism/data/stash/genai_rhyme_prompts/pairtree.hashstash.raw+b64/data.db)\n",
      "  * from_cache: False\n",
      "\n",
      "Here is a poem that does not rhyme:\n",
      "\n",
      "The Whisper of the Wind\n",
      "\n",
      "Across the vast expanse, the wind whispers,\n",
      "Caressing the earth with its gentle breath.\n",
      "It dances through the swaying trees,\n",
      "Carrying the scent of blossoms in its wake.\n",
      "\n",
      "The wind's voice, a symphony of motion,\n",
      "Echoes through the valleys and over the hills.\n",
      "It lifts the leaves, rustling their secrets,\n",
      "And carries the dreams of the world aloft.\n",
      "\n",
      "In its embrace, the world feels alive,\n",
      "Pulsing with the rhythm of nature's heart.\n",
      "The wind, a constant companion, a faithful guide,\n",
      "Reminds us to listen, to feel, to be alive."
     ]
    }
   ],
   "source": [
    "# Code\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from generative_formalism import *\n",
    "\n",
    "printm('# Generative poems: prompted for un/rhymed poems')\n",
    "printm('## Prompting models')\n",
    "printm('Edit `PROMPTS` and `MODEL_LIST` in `constants.py` to change prompts and models.')\n",
    "\n",
    "printm('### Current prompts ')\n",
    "describe_prompts()\n",
    "\n",
    "printm('### Current models')\n",
    "describe_models()\n",
    "\n",
    "# Run a demo?\n",
    "if REPLICATE_LLM_DEMO and check_api_keys():\n",
    "\n",
    "    demo_model, demo_prompt = get_demo_model_prompt(verbose=True)\n",
    "    print(f'* Demo model: {demo_model}')\n",
    "    print(f'* Demo prompt: {demo_prompt}\\n')\n",
    "\n",
    "    response_str = generate_rhyme_prompt_text(\n",
    "        model=demo_model,\n",
    "        prompt=demo_prompt,\n",
    "        verbose=True,\n",
    "        force=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Run if enabled\n",
    "if REPLICATE_LLM_MANY and N_TO_GENERATE > 0:\n",
    "    documentation(generate_more_poems_from_rhyme_prompts)\n",
    "    \n",
    "    # Run\n",
    "    df_newdata = generate_more_poems_from_rhyme_prompts(\n",
    "        # df_sofar=pd.DataFrame(),\n",
    "        n=N_TO_GENERATE,\n",
    "        models = MODEL_LIST,\n",
    "        prompts = PROMPT_LIST,\n",
    "        temperatures=[DEFAULT_TEMPERATURE],\n",
    "        verbose=DEFAULT_VERBOSE,\n",
    "        force=True,\n",
    "        max_n_combo=25\n",
    "    )\n",
    "\n",
    "    # Display\n",
    "    display(df_newdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T21:51:10.368970Z",
     "iopub.status.busy": "2025-09-15T21:51:10.368889Z",
     "iopub.status.idle": "2025-09-15T21:51:10.373029Z",
     "shell.execute_reply": "2025-09-15T21:51:10.372795Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of prompting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T21:51:10.374169Z",
     "iopub.status.busy": "2025-09-15T21:51:10.374101Z",
     "iopub.status.idle": "2025-09-15T21:51:11.760205Z",
     "shell.execute_reply": "2025-09-15T21:51:11.759932Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if REPLICATE_LLM_DEMO:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting with many models/prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting all promptings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docs\n",
    "printm(f'## Collecting all promptings')\n",
    "documentation(get_genai_rhyme_promptings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printm(f'### Data used in paper')\n",
    "\n",
    "df_genai_rhyme_promptings_as_in_paper = get_genai_rhyme_promptings(\n",
    "    as_in_paper=True,\n",
    "    display=False, \n",
    "    verbose=True\n",
    ")\n",
    "df_genai_rhyme_promptings_as_in_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data replicated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genai_rhyme_promptings_as_replicated = get_genai_rhyme_promptings(\n",
    "    as_in_paper=False,\n",
    "    as_replicated=True,\n",
    "    display=False, \n",
    "    verbose=True\n",
    ")\n",
    "df_genai_rhyme_promptings_as_replicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating paper + replicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All together\n",
    "df_all_rhyme_promptings = get_genai_rhyme_promptings(\n",
    "    as_in_paper=True,\n",
    "    as_replicated=True,\n",
    "    display=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "describe_qual(df_all_rhyme_promptings.data_source)\n",
    "df_all_rhyme_promptings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
