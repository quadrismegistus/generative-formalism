{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting for un/rhyming poems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting prompts and models\n",
    "\n",
    "Edit `PROMPTS` and `MODEL_LIST` in `constants.py` to change prompts and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from generative_formalism import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`describe_prompts`**\n",
       "\n",
       "```md\n",
       "Print a description of the prompts with statistics and details.\n",
       "    \n",
       "    Args:\n",
       "        prompts: List of prompt strings to describe. Defaults to PROMPT_LIST.\n",
       "        prompt_to_type: Dictionary mapping prompts to their types. Defaults to PROMPT_TO_TYPE.\n",
       "    \n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documentation(describe_prompts, signature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 23 unique prompts\n",
      "* 3 prompt types\n",
      "\n",
      "* List of prompts:\n",
      "  ['Write a poem in ballad stanzas.',\n",
      " \"Write an ryhmed poem in the style of Shakespeare's sonnets.\",\n",
      " 'Write a long poem that does rhyme.',\n",
      " 'Write a poem in the style of Emily Dickinson.',\n",
      " 'Write a poem in heroic couplets.',\n",
      " 'Write an rhyming poem.',\n",
      " 'Write a poem (with 20+ lines) that rhymes.',\n",
      " 'Write a poem that does rhyme.',\n",
      " 'Write a short poem that does rhyme.',\n",
      " 'Write a poem that does NOT rhyme.',\n",
      " 'Write a poem (with 20+ lines) that does NOT rhyme.',\n",
      " 'Write a long poem that does NOT rhyme.',\n",
      " 'Write a poem in the style of Walt Whitman.',\n",
      " 'Write a poem in free verse.',\n",
      " 'Write a poem in blank verse.',\n",
      " 'Write an unrhymed poem.',\n",
      " 'Write a short poem that does NOT rhyme.',\n",
      " 'Write a poem (with 20+ lines).',\n",
      " 'Write a long poem.',\n",
      " 'Write a poem in groups of two lines.',\n",
      " 'Write a poem.',\n",
      " 'Write a poem in stanzas of 4 lines each.',\n",
      " 'Write a short poem.']\n",
      "\n",
      "* List of prompt types:\n",
      "  {'DO_rhyme': ['Write a poem in ballad stanzas.',\n",
      "              \"Write an ryhmed poem in the style of Shakespeare's sonnets.\",\n",
      "              'Write a long poem that does rhyme.',\n",
      "              'Write a poem in the style of Emily Dickinson.',\n",
      "              'Write a poem in heroic couplets.',\n",
      "              'Write an rhyming poem.',\n",
      "              'Write a poem (with 20+ lines) that rhymes.',\n",
      "              'Write a poem that does rhyme.',\n",
      "              'Write a short poem that does rhyme.'],\n",
      " 'MAYBE_rhyme': ['Write a poem (with 20+ lines).',\n",
      "                 'Write a long poem.',\n",
      "                 'Write a poem in groups of two lines.',\n",
      "                 'Write a poem.',\n",
      "                 'Write a poem in stanzas of 4 lines each.',\n",
      "                 'Write a short poem.'],\n",
      " 'do_NOT_rhyme': ['Write a poem that does NOT rhyme.',\n",
      "                  'Write a poem (with 20+ lines) that does NOT rhyme.',\n",
      "                  'Write a long poem that does NOT rhyme.',\n",
      "                  'Write a poem in the style of Walt Whitman.',\n",
      "                  'Write a poem in free verse.',\n",
      "                  'Write a poem in blank verse.',\n",
      "                  'Write an unrhymed poem.',\n",
      "                  'Write a short poem that does NOT rhyme.']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PROMPT_LIST = ''\n",
    "# PROMPT_TO_CATEGORY = {}\n",
    "\n",
    "describe_prompts(\n",
    "    prompts=PROMPT_LIST,\n",
    "    prompt_to_type=PROMPT_TO_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 11 models (counting parameter changes)\n",
      "  * 6 model types (ChatGPT, Claude, DeepSeek, Gemini, Llama, Olmo)\n",
      "  * Using models:\n",
      "  {   'ChatGPT': ['gpt-3.5-turbo', 'gpt-4-turbo'],\n",
      "    'Claude': [   'claude-3-haiku-20240307',\n",
      "                  'claude-3-opus-20240229',\n",
      "                  'claude-3-sonnet-20240229'],\n",
      "    'DeepSeek': ['deepseek/deepseek-chat'],\n",
      "    'Gemini': ['gemini-pro'],\n",
      "    'Llama': ['ollama/llama3.1:70b', 'ollama/llama3.1:8b'],\n",
      "    'Olmo': ['ollama/olmo2', 'ollama/olmo2:13b']}\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Prompts\n",
    "\n",
    "# To override:\n",
    "\n",
    "# MODEL_LIST = []\n",
    "# MODEL_TO_NAME = {}\n",
    "# MODEL_TO_TYPE = {}\n",
    "\n",
    "describe_models(models=MODEL_LIST, model_to_type=MODEL_TO_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documentation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdocumentation\u001b[49m(check_api_keys)\n\u001b[32m      2\u001b[39m check_api_keys()\n",
      "\u001b[31mNameError\u001b[39m: name 'documentation' is not defined"
     ]
    }
   ],
   "source": [
    "documentation(check_api_keys)\n",
    "check_api_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`generate_rhyme_prompt_text`**\n",
       "\n",
       "```md\n",
       "\n",
       "    Convenience function for generate_text using rhyme stash.\n",
       "\n",
       "    Args:\n",
       "        args: Arguments for generate_text\n",
       "        stash: Stash to use for caching. Defaults to STASH_GENAI_RHYME_PROMPTS.\n",
       "        verbose: Whether to print verbose output. Defaults to True.\n",
       "        kwargs: Keyword arguments for generate_text\n",
       "\n",
       "    Returns:\n",
       "        str: The generated text\n",
       "    \n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documentation(generate_rhyme_prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`generate_text`**\n",
       "\n",
       "```md\n",
       "Generate text with caching support (synchronous interface).\n",
       "    \n",
       "    This is the main text generation function that includes caching capabilities.\n",
       "    Results are cached based on the combination of model, prompt, temperature, and system_prompt.\n",
       "    \n",
       "    Args:\n",
       "        model: The model identifier\n",
       "        prompt: The user prompt/input text\n",
       "        temperature: Sampling temperature for text generation (0.0-1.0)\n",
       "        system_prompt: Optional system prompt/instruction\n",
       "        verbose: If True, print the complete response to stdout\n",
       "        force: If True, bypass cache and force new generation\n",
       "        stash: Cache storage backend for results\n",
       "        \n",
       "    Returns:\n",
       "        str: The complete generated text response (from cache or new generation)\n",
       "    \n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documentation(generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`stream_llm`**\n",
       "\n",
       "```md\n",
       "Universal streaming interface for language models.\n",
       "    \n",
       "    Automatically routes to the appropriate streaming function based on the model name.\n",
       "    Google models (containing 'gemini') use the Google Generative AI API,\n",
       "    all others use LiteLLM.\n",
       "    \n",
       "    Args:\n",
       "        model: The model identifier\n",
       "        prompt: The user prompt/input text\n",
       "        temperature: Sampling temperature for text generation (0.0-1.0)\n",
       "        system_prompt: Optional system prompt/instruction\n",
       "        verbose: If True, print tokens to stdout as they're generated\n",
       "        \n",
       "    Yields:\n",
       "        str: Individual tokens/text chunks from the model response\n",
       "    \n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documentation(stream_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo of prompting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REPLICATE_LLM_DEMO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mREPLICATE_LLM_DEMO\u001b[49m:\n\u001b[32m      2\u001b[39m     demo_model, demo_prompt = get_demo_model_prompt()\n\u001b[32m      4\u001b[39m     response_str = generate_rhyme_prompt_text(\n\u001b[32m      5\u001b[39m         model=DEMO_MODEL,\n\u001b[32m      6\u001b[39m         prompt=DEMO_PROMPT,\n\u001b[32m      7\u001b[39m         verbose=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m         force=REPLICATE_OVERWRITE\n\u001b[32m      9\u001b[39m     )\n",
      "\u001b[31mNameError\u001b[39m: name 'REPLICATE_LLM_DEMO' is not defined"
     ]
    }
   ],
   "source": [
    "if REPLICATE_LLM_DEMO:\n",
    "    demo_model, demo_prompt = get_demo_model_prompt()\n",
    "\n",
    "    response_str = generate_rhyme_prompt_text(\n",
    "        model=DEMO_MODEL,\n",
    "        prompt=DEMO_PROMPT,\n",
    "        verbose=True,\n",
    "        force=REPLICATE_OVERWRITE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate more poems from rhyme prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`generate_more_poems_from_rhyme_prompts`**\n",
       "\n",
       "```md\n",
       "\n",
       "    Generate more poems from rhyme prompts using various models and configurations.\n",
       "    \n",
       "    This function generates additional poems by sampling from available models and prompts,\n",
       "    with intelligent prioritization of underrepresented combinations to ensure balanced\n",
       "    data collection across different model-prompt pairs.\n",
       "    \n",
       "    Args:\n",
       "        n (int, optional): Number of poems to generate. Defaults to 3.\n",
       "        df_sofar (pd.DataFrame, optional): Existing dataframe of generated poems to build upon.\n",
       "            If None, loads all existing rhyme promptings. Defaults to None.\n",
       "        models (list, optional): List of model identifiers to use for generation.\n",
       "            Defaults to MODEL_LIST from constants.\n",
       "        prompts (list, optional): List of prompt templates to use for generation.\n",
       "            Defaults to PROMPT_LIST from constants.\n",
       "        temperatures (list, optional): List of temperature values for generation.\n",
       "            If None, uses default temperature. Defaults to None.\n",
       "        verbose (bool, optional): Whether to print progress and status information.\n",
       "            Defaults to True.\n",
       "        force (bool, optional): Whether to force regeneration even if cached results exist.\n",
       "            Defaults to False.\n",
       "        max_n_combo (int, optional): Maximum number of entries allowed per model-prompt\n",
       "            combination. If provided, model-prompt pairs that already have this many\n",
       "            or more entries will be excluded from selection. Defaults to None (no limit).\n",
       "    \n",
       "    Returns:\n",
       "        list: List of dictionaries containing generated poem data, including model,\n",
       "            prompt, temperature, generated text, and metadata.\n",
       "    \n",
       "    Note:\n",
       "        The function uses inverse probability weighting to prioritize model-prompt\n",
       "        combinations that have been used less frequently, ensuring balanced sampling\n",
       "        across the available options. Models that consistently fail are temporarily\n",
       "        excluded from further attempts.\n",
       "    \n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documentation(generate_more_poems_from_rhyme_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> deepseek/deepseek-chat (n_model=707, n_prompt=159, n_combo=11): \"Write a short poem that does rhyme.\":  10%|█         | 10/100 [00:52<09:21,  6.24s/it]     "
     ]
    }
   ],
   "source": [
    "# Set params\n",
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    # 'claude-3-opus-20240229',\n",
    "    # 'claude-3-sonnet-20240229',\n",
    "    'deepseek/deepseek-chat',\n",
    "    # 'gemini-pro',\n",
    "    # 'gpt-3.5-turbo',\n",
    "    # 'gpt-4-turbo',\n",
    "    # 'ollama/llama3.1:70b',\n",
    "    # 'ollama/llama3.1:8b',\n",
    "    # 'ollama/olmo2',\n",
    "    # 'ollama/olmo2:13b'\n",
    "]\n",
    "n = 100\n",
    "verbose = False\n",
    "\n",
    "# Run if enabled\n",
    "df_newdata = pd.DataFrame()\n",
    "if n > 0 and REPLICATE_LLM_DATA:  \n",
    "    df_newdata = generate_more_poems_from_rhyme_prompts(\n",
    "        n=n,\n",
    "        models = models,\n",
    "        prompts = PROMPT_LIST,\n",
    "        temperatures=[DEFAULT_TEMPERATURE],\n",
    "        verbose=False,\n",
    "        force=REPLICATE_OVERWRITE,\n",
    "        max_n_combo=25\n",
    "    )\n",
    "\n",
    "# Show the new data\n",
    "df_newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting replicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`get_genai_rhyme_promptings_as_replicated`**\n",
       "\n",
       "```md\n",
       "None\n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documentation(get_genai_rhyme_promptings_as_replicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Collecting genai rhyme promptings as replicated here\n",
      "  * Collecting from /Users/ryan/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl\n",
      "  * 329 generated poems\n",
      "  * 329 generated responses\n",
      "  * 224 unique responses\n",
      "  * 224 unique poems\n",
      "  * 23 unique prompts\n",
      "  * 3 unique prompt types\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>txt</th>\n",
       "      <th>num_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>DO_rhyme</td>\n",
       "      <td>Write a long poem that does rhyme.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.3887</td>\n",
       "      <td>In a world of chaos and strife,\\nWhere darknes...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a poem in free verse.</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>The breeze caresses my face,\\nGently rustling ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a poem that does NOT rhyme.</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>Beneath the endless sky,\\nWhispers of the wind...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a short poem that does NOT rhyme.</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>Whispers of the wind,\\nEchoing through the tre...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a long poem that does NOT rhyme.</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>In the stillness of the night,\\nWhen the world...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt_type                                   prompt                    model  temperature                                                txt  num_lines\n",
       "79       DO_rhyme       Write a long poem that does rhyme.            gpt-3.5-turbo       0.3887  In a world of chaos and strife,\\nWhere darknes...         32\n",
       "207  do_NOT_rhyme              Write a poem in free verse.  claude-3-haiku-20240307       0.7000  The breeze caresses my face,\\nGently rustling ...         17\n",
       "34   do_NOT_rhyme        Write a poem that does NOT rhyme.  claude-3-haiku-20240307       0.7000  Beneath the endless sky,\\nWhispers of the wind...         15\n",
       "211  do_NOT_rhyme  Write a short poem that does NOT rhyme.  claude-3-haiku-20240307       0.7000  Whispers of the wind,\\nEchoing through the tre...         12\n",
       "181  do_NOT_rhyme   Write a long poem that does NOT rhyme.  claude-3-haiku-20240307       0.7000  In the stillness of the night,\\nWhen the world...         24"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genai_rhyme_promptings_as_replicated = get_genai_rhyme_promptings_as_replicated(display=False)\n",
    "df_genai_rhyme_promptings_as_replicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Collecting genai rhyme promptings as used in paper\n",
      "  * Collecting from /Users/ryan/github/generative-formalism/data/corpus_genai_promptings.csv.gz\n",
      "  * 17,988 generated responses\n",
      "  * 16,935 unique responses\n",
      "  * 16,871 unique poems\n",
      "  * 23 unique prompts\n",
      "  * 3 unique prompt types\n",
      "\n",
      "* Collecting genai rhyme promptings as replicated here\n",
      "  * Collecting from /Users/ryan/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl\n",
      "  * 329 generated poems\n",
      "  * 329 generated responses\n",
      "  * 224 unique responses\n",
      "  * 224 unique poems\n",
      "  * 23 unique prompts\n",
      "  * 3 unique prompt types\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>txt</th>\n",
       "      <th>num_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e0cef7a6</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a poem (with 20+ lines) that does NOT rh...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.568162</td>\n",
       "      <td>In the stillness of the night, I find myself l...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62239ba3</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a poem that does NOT rhyme.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>1.214958</td>\n",
       "      <td>In the darkness of the night,\\nI wander alone,...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1adb546c</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a poem that does NOT rhyme.</td>\n",
       "      <td>ollama/llama3.1:8b</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>Silence falls like a blanket over the city\\nA ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02cb4c92</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a long poem that does NOT rhyme.</td>\n",
       "      <td>ollama/llama3.1:70b</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>In the depths of existence, where shadows roam...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20a14bc7</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a poem in the style of Walt Whitman.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.376548</td>\n",
       "      <td>O captain, my captain, the journey is long\\nTh...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>DO_rhyme</td>\n",
       "      <td>Write a long poem that does rhyme.</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>In the heart of the forest, where shadows danc...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>DO_rhyme</td>\n",
       "      <td>Write a poem that does rhyme.</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>The autumn breeze blows soft and cool,\\nCaress...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a long poem that does NOT rhyme.</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>The gentle breeze caresses my face,\\nCarrying ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a poem (with 20+ lines) that does NOT rh...</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>The whispers of the wind caress my face,\\nCarr...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>do_NOT_rhyme</td>\n",
       "      <td>Write a poem in free verse.</td>\n",
       "      <td>deepseek/deepseek-chat</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>The old oak knows the weight of time,\\nnot in ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14011 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           prompt_type                                             prompt                    model  temperature                                                txt  num_lines\n",
       "e0cef7a6  do_NOT_rhyme  Write a poem (with 20+ lines) that does NOT rh...            gpt-3.5-turbo     0.568162  In the stillness of the night, I find myself l...         24\n",
       "62239ba3  do_NOT_rhyme                  Write a poem that does NOT rhyme.            gpt-3.5-turbo     1.214958  In the darkness of the night,\\nI wander alone,...         16\n",
       "1adb546c  do_NOT_rhyme                  Write a poem that does NOT rhyme.       ollama/llama3.1:8b     0.700000  Silence falls like a blanket over the city\\nA ...         12\n",
       "02cb4c92  do_NOT_rhyme             Write a long poem that does NOT rhyme.      ollama/llama3.1:70b     0.700000  In the depths of existence, where shadows roam...         28\n",
       "20a14bc7  do_NOT_rhyme         Write a poem in the style of Walt Whitman.            gpt-3.5-turbo     0.376548  O captain, my captain, the journey is long\\nTh...         16\n",
       "...                ...                                                ...                      ...          ...                                                ...        ...\n",
       "258           DO_rhyme                 Write a long poem that does rhyme.            gpt-3.5-turbo     0.700000  In the heart of the forest, where shadows danc...         36\n",
       "87            DO_rhyme                      Write a poem that does rhyme.  claude-3-haiku-20240307     0.292400  The autumn breeze blows soft and cool,\\nCaress...         12\n",
       "178       do_NOT_rhyme             Write a long poem that does NOT rhyme.  claude-3-haiku-20240307     0.700000  The gentle breeze caresses my face,\\nCarrying ...         36\n",
       "198       do_NOT_rhyme  Write a poem (with 20+ lines) that does NOT rh...  claude-3-haiku-20240307     0.700000  The whispers of the wind caress my face,\\nCarr...         28\n",
       "241       do_NOT_rhyme                        Write a poem in free verse.   deepseek/deepseek-chat     0.700000  The old oak knows the weight of time,\\nnot in ...         20\n",
       "\n",
       "[14011 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> ollama/llama3.1:8b (n_model=1,523, n_prompt=209, n_combo=2): \"Write a short poem that does NOT rhyme.\":  28%|██▊       | 28/100 [00:30<00:17,  4.13it/s]"
     ]
    }
   ],
   "source": [
    "# All together\n",
    "df_all_rhyme_promptings = get_all_genai_rhyme_promptings(display=False)\n",
    "df_all_rhyme_promptings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
