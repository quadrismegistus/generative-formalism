{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting for un/rhyming poems at scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gemini API key\n",
      "✓ OpenAI API key\n",
      "✓ Anthropic API key\n",
      "✓ DeepSeek API key\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from generative_formalism import *\n",
    "check_api_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set params\n",
    "MODELS_LIST_NOW = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'claude-3-opus-20240229',\n",
    "    'claude-3-sonnet-20240229',\n",
    "    'deepseek/deepseek-chat',\n",
    "    'gemini-pro',\n",
    "    'gpt-3.5-turbo',\n",
    "    'gpt-4-turbo',\n",
    "    'ollama/llama3.1:70b',\n",
    "    'ollama/llama3.1:8b',\n",
    "    'ollama/olmo2',\n",
    "    'ollama/olmo2:13b'\n",
    "]\n",
    "\n",
    "PROMPT_LIST_NOW = PROMPT_LIST\n",
    "\n",
    "# PROMPT_LIST_NOW = [\n",
    "#  'Write a poem.',\n",
    "#  'Write a long poem.',\n",
    "#  'Write a short poem.',\n",
    "#  'Write an rhyming poem.',\n",
    "#  'Write an unrhymed poem.',\n",
    "#  'Write a poem in free verse.',\n",
    "#  'Write a poem in blank verse.',\n",
    "#  'Write a poem that does rhyme.',\n",
    "#  'Write a poem (with 20+ lines).',\n",
    "#  'Write a poem in ballad stanzas.',\n",
    "#  'Write a poem in heroic couplets.',\n",
    "#  'Write a poem that does NOT rhyme.',\n",
    "#  'Write a long poem that does rhyme.',\n",
    "#  'Write a short poem that does rhyme.',\n",
    "#  'Write a poem in groups of two lines.',\n",
    "#  'Write a long poem that does NOT rhyme.',\n",
    "#  'Write a short poem that does NOT rhyme.',\n",
    "#  'Write a poem in stanzas of 4 lines each.',\n",
    "#  'Write a poem (with 20+ lines) that rhymes.',\n",
    "#  'Write a poem in the style of Walt Whitman.',\n",
    "#  'Write a poem in the style of Emily Dickinson.',\n",
    "#  'Write a poem (with 20+ lines) that does NOT rhyme.',\n",
    "#  \"Write an ryhmed poem in the style of Shakespeare's sonnets.\"\n",
    "# ]\n",
    "\n",
    "\n",
    "N_TO_GENERATE_NOW = 10\n",
    "\n",
    "VERBOSE_NOW = False\n",
    "\n",
    "TEMPERATURE_NOW = DEFAULT_TEMPERATURE  # 0.7\n",
    "\n",
    "REPLICATE_OVERWRITE_NOW = True\n",
    "\n",
    "REPLICATE_LLM_DATA_NOW = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### `generate_more_poems_from_rhyme_prompts`\n",
       "\n",
       "```md\n",
       "\n",
       "    Generate more poems from rhyme prompts using various models and configurations.\n",
       "    \n",
       "    This function generates additional poems by sampling from available models and prompts,\n",
       "    with intelligent prioritization of underrepresented combinations to ensure balanced\n",
       "    data collection across different model-prompt pairs.\n",
       "    \n",
       "    Args:\n",
       "        n (int, optional): Number of poems to generate. Defaults to 3.\n",
       "        df_sofar (pd.DataFrame, optional): Existing dataframe of generated poems to build upon.\n",
       "            If None, loads all existing rhyme promptings. Defaults to None.\n",
       "        models (list, optional): List of model identifiers to use for generation.\n",
       "            Defaults to MODEL_LIST from constants.\n",
       "        prompts (list, optional): List of prompt templates to use for generation.\n",
       "            Defaults to PROMPT_LIST from constants.\n",
       "        temperatures (list, optional): List of temperature values for generation.\n",
       "            If None, uses default temperature. Defaults to None.\n",
       "        verbose (bool, optional): Whether to print progress and status information.\n",
       "            Defaults to True.\n",
       "        force (bool, optional): Whether to force regeneration even if cached results exist.\n",
       "            Defaults to False.\n",
       "        max_n_combo (int, optional): Maximum number of entries allowed per model-prompt\n",
       "            combination. If provided, model-prompt pairs that already have this many\n",
       "            or more entries will be excluded from selection. Defaults to None (no limit).\n",
       "    \n",
       "    Returns:\n",
       "        list: List of dictionaries containing generated poem data, including model,\n",
       "            prompt, temperature, generated text, and metadata.\n",
       "    \n",
       "    Note:\n",
       "        The function uses inverse probability weighting to prioritize model-prompt\n",
       "        combinations that have been used less frequently, ensuring balanced sampling\n",
       "        across the available options. Models that consistently fail are temporarily\n",
       "        excluded from further attempts.\n",
       "    \n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generates poems according to least used model-prompt pairs\n",
    "documentation(generate_more_poems_from_rhyme_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Use get_genai_rhyme_promptings_by(..., as_in_paper=True) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run if enabled\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m REPLICATE_LLM_DATA_NOW \u001b[38;5;129;01mand\u001b[39;00m N_TO_GENERATE_NOW > \u001b[32m0\u001b[39m:\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     df_newdata = \u001b[43mgenerate_more_poems_from_rhyme_prompts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# df_sofar=pd.DataFrame(),\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_TO_GENERATE_NOW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODELS_LIST_NOW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPT_LIST_NOW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTEMPERATURE_NOW\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVERBOSE_NOW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m=\u001b[49m\u001b[43mREPLICATE_OVERWRITE_NOW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_n_combo\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Display\u001b[39;00m\n\u001b[32m     18\u001b[39m     display(df_newdata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/generative-formalism/notebooks/../generative_formalism/rhyme/rhyme_promptings.py:67\u001b[39m, in \u001b[36mgenerate_more_poems_from_rhyme_prompts\u001b[39m\u001b[34m(n, df_sofar, models, prompts, temperatures, verbose, force, max_n_combo)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mGenerate more poems from rhyme prompts using various models and configurations.\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m \u001b[33;03m    excluded from further attempts.\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Prioritize underrepresented models and prompts\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m df = \u001b[43mget_all_genai_rhyme_promptings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m df_sofar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m df_sofar\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Create copies to modify\u001b[39;00m\n\u001b[32m     70\u001b[39m models = \u001b[38;5;28mlist\u001b[39m(models)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/generative-formalism/notebooks/../generative_formalism/rhyme/rhyme_promptings.py:306\u001b[39m, in \u001b[36mget_all_genai_rhyme_promptings\u001b[39m\u001b[34m(display, verbose, *args, **kwargs)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_all_genai_rhyme_promptings\u001b[39m(*args, display=\u001b[38;5;28;01mFalse\u001b[39;00m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m, **kwargs):\n\u001b[32m    294\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    295\u001b[39m \u001b[33;03m    Collect all genai rhyme promptings from both the paper and replicated here.\u001b[39;00m\n\u001b[32m    296\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    304\u001b[39m \u001b[33;03m        pd.DataFrame: All genai rhyme promptings\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     df1 = \u001b[43mget_genai_rhyme_promptings_by\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_in_paper\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_replicated\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m     df2 = get_genai_rhyme_promptings_by(*args, as_in_paper=\u001b[38;5;28;01mFalse\u001b[39;00m, as_replicated=\u001b[38;5;28;01mTrue\u001b[39;00m, display=\u001b[38;5;28;01mFalse\u001b[39;00m, verbose=verbose, **kwargs)\n\u001b[32m    308\u001b[39m     odf = pd.concat([df1, df2])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/generative-formalism/notebooks/../generative_formalism/rhyme/rhyme_promptings.py:619\u001b[39m, in \u001b[36mget_genai_rhyme_promptings_by\u001b[39m\u001b[34m(as_in_paper, as_replicated, verbose, display, *args, **kwargs)\u001b[39m\n\u001b[32m    611\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_genai_rhyme_promptings_as_replicated(\n\u001b[32m    612\u001b[39m         *args,\n\u001b[32m    613\u001b[39m         verbose=verbose,\n\u001b[32m    614\u001b[39m         display=display,\n\u001b[32m    615\u001b[39m         **kwargs,\n\u001b[32m    616\u001b[39m     )\n\u001b[32m    618\u001b[39m \u001b[38;5;66;03m# Default: as_in_paper\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_genai_rhyme_promptings_as_in_paper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/generative-formalism/notebooks/../generative_formalism/rhyme/rhyme_promptings.py:286\u001b[39m, in \u001b[36mget_genai_rhyme_promptings_as_in_paper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_genai_rhyme_promptings_as_in_paper\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUse get_genai_rhyme_promptings_by(..., as_in_paper=True) instead\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Use get_genai_rhyme_promptings_by(..., as_in_paper=True) instead"
     ]
    }
   ],
   "source": [
    "# Run if enabled\n",
    "\n",
    "if REPLICATE_LLM_DATA_NOW and N_TO_GENERATE_NOW > 0:\n",
    "    \n",
    "    # Run\n",
    "    df_newdata = generate_more_poems_from_rhyme_prompts(\n",
    "        # df_sofar=pd.DataFrame(),\n",
    "        n=N_TO_GENERATE_NOW,\n",
    "        models = MODELS_LIST_NOW,\n",
    "        prompts = PROMPT_LIST_NOW,\n",
    "        temperatures=[TEMPERATURE_NOW],\n",
    "        verbose=VERBOSE_NOW,\n",
    "        force=REPLICATE_OVERWRITE_NOW,\n",
    "        max_n_combo=25\n",
    "    )\n",
    "\n",
    "    # Display\n",
    "    display(df_newdata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
