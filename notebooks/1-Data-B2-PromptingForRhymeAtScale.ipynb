{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting for un/rhyming poems at scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from generative_formalism import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set params\n",
    "MODELS_LIST_NOW = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    # 'claude-3-opus-20240229',\n",
    "    # 'claude-3-sonnet-20240229',\n",
    "    'deepseek/deepseek-chat',\n",
    "    # 'gemini-pro',\n",
    "    # 'gpt-3.5-turbo',\n",
    "    # 'gpt-4-turbo',\n",
    "    # 'ollama/llama3.1:70b',\n",
    "    # 'ollama/llama3.1:8b',\n",
    "    # 'ollama/olmo2',\n",
    "    # 'ollama/olmo2:13b'\n",
    "]\n",
    "\n",
    "PROMPT_LIST_NOW = PROMPT_LIST\n",
    "\n",
    "# PROMPT_LIST_NOW = [\n",
    "#  'Write a poem.',\n",
    "#  'Write a long poem.',\n",
    "#  'Write a short poem.',\n",
    "#  'Write an rhyming poem.',\n",
    "#  'Write an unrhymed poem.',\n",
    "#  'Write a poem in free verse.',\n",
    "#  'Write a poem in blank verse.',\n",
    "#  'Write a poem that does rhyme.',\n",
    "#  'Write a poem (with 20+ lines).',\n",
    "#  'Write a poem in ballad stanzas.',\n",
    "#  'Write a poem in heroic couplets.',\n",
    "#  'Write a poem that does NOT rhyme.',\n",
    "#  'Write a long poem that does rhyme.',\n",
    "#  'Write a short poem that does rhyme.',\n",
    "#  'Write a poem in groups of two lines.',\n",
    "#  'Write a long poem that does NOT rhyme.',\n",
    "#  'Write a short poem that does NOT rhyme.',\n",
    "#  'Write a poem in stanzas of 4 lines each.',\n",
    "#  'Write a poem (with 20+ lines) that rhymes.',\n",
    "#  'Write a poem in the style of Walt Whitman.',\n",
    "#  'Write a poem in the style of Emily Dickinson.',\n",
    "#  'Write a poem (with 20+ lines) that does NOT rhyme.',\n",
    "#  \"Write an ryhmed poem in the style of Shakespeare's sonnets.\"\n",
    "# ]\n",
    "\n",
    "\n",
    "N_TO_GENERATE_NOW = 3\n",
    "\n",
    "VERBOSE_NOW = True\n",
    "\n",
    "TEMPERATURE_NOW = DEFAULT_TEMPERATURE  # 0.7\n",
    "\n",
    "REPLICATE_OVERWRITE_NOW = True\n",
    "\n",
    "REPLICATE_LLM_DATA_NOW = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gemini API key\n",
      "✓ OpenAI API key\n",
      "✓ Anthropic API key\n",
      "✓ DeepSeek API key\n"
     ]
    }
   ],
   "source": [
    "check_api_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`generate_more_poems_from_rhyme_prompts`**\n",
       "\n",
       "```md\n",
       "\n",
       "    Generate more poems from rhyme prompts using various models and configurations.\n",
       "    \n",
       "    This function generates additional poems by sampling from available models and prompts,\n",
       "    with intelligent prioritization of underrepresented combinations to ensure balanced\n",
       "    data collection across different model-prompt pairs.\n",
       "    \n",
       "    Args:\n",
       "        n (int, optional): Number of poems to generate. Defaults to 3.\n",
       "        df_sofar (pd.DataFrame, optional): Existing dataframe of generated poems to build upon.\n",
       "            If None, loads all existing rhyme promptings. Defaults to None.\n",
       "        models (list, optional): List of model identifiers to use for generation.\n",
       "            Defaults to MODEL_LIST from constants.\n",
       "        prompts (list, optional): List of prompt templates to use for generation.\n",
       "            Defaults to PROMPT_LIST from constants.\n",
       "        temperatures (list, optional): List of temperature values for generation.\n",
       "            If None, uses default temperature. Defaults to None.\n",
       "        verbose (bool, optional): Whether to print progress and status information.\n",
       "            Defaults to True.\n",
       "        force (bool, optional): Whether to force regeneration even if cached results exist.\n",
       "            Defaults to False.\n",
       "        max_n_combo (int, optional): Maximum number of entries allowed per model-prompt\n",
       "            combination. If provided, model-prompt pairs that already have this many\n",
       "            or more entries will be excluded from selection. Defaults to None (no limit).\n",
       "    \n",
       "    Returns:\n",
       "        list: List of dictionaries containing generated poem data, including model,\n",
       "            prompt, temperature, generated text, and metadata.\n",
       "    \n",
       "    Note:\n",
       "        The function uses inverse probability weighting to prioritize model-prompt\n",
       "        combinations that have been used less frequently, ensuring balanced sampling\n",
       "        across the available options. Models that consistently fail are temporarily\n",
       "        excluded from further attempts.\n",
       "    \n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generates poems according to least used model-prompt pairs\n",
    "documentation(generate_more_poems_from_rhyme_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Collecting genai rhyme promptings as used in paper\n",
      "  * Collecting from /Users/ryan/github/generative-formalism/data/corpus_genai_promptings.csv.gz\n",
      "  * 17,988 generated responses\n",
      "  * 16,935 unique responses\n",
      "  * 16,871 unique poems\n",
      "  * 23 unique prompts\n",
      "  * 3 unique prompt types\n",
      "\n",
      "* Collecting genai rhyme promptings as replicated here\n",
      "  * Collecting from /Users/ryan/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl\n",
      "  * 460 generated poems\n",
      "  * 460 generated responses\n",
      "  * 340 unique responses\n",
      "  * 340 unique poems\n",
      "  * 23 unique prompts\n",
      "  * 3 unique prompt types\n",
      "  * Filtered out 202 model-prompt combinations with >= 25 entries\n",
      "  * Using 2 models and 4 prompts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> deepseek/deepseek-chat (n_model=710, n_prompt=205, n_combo=21): \"Write a short poem that does NOT rhyme.\":   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generating text\n",
      "  * model: deepseek/deepseek-chat\n",
      "  * prompt: Write a short poem that does NOT rhyme.\n",
      "  * temperature: 0.7\n",
      "  * force: True\n",
      "  * stash: JSONLHashStash(~/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl)\n",
      "  * from_cache: False\n",
      "\n",
      "The sun climbs the morning hill.\n",
      "A single cloud, a breath of white.\n",
      "The old pine stands on the ridge,\n",
      "its shadow a long, cool drink for the earth.\n",
      "No two stones alike in the dry creek bed.\n",
      "Silence holds the space between the notes.\n",
      "This is the truth the mountain knows."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> deepseek/deepseek-chat (n_model=711, n_prompt=206, n_combo=22): \"Write a short poem that does NOT rhyme.\":  33%|███▎      | 1/3 [00:07<00:14,  7.11s/it]"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generating text\n",
      "  * model: deepseek/deepseek-chat\n",
      "  * prompt: Write a short poem that does NOT rhyme.\n",
      "  * temperature: 0.7\n",
      "  * force: True\n",
      "  * stash: JSONLHashStash(~/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl)\n",
      "  * from_cache: False\n",
      "\n",
      "The sun climbs the morning.\n",
      "A single leaf falls,\n",
      "spiraling without sound.\n",
      "Shadows grow long and lean.\n",
      "The moon is a pale cup,\n",
      "waiting for the dark."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> claude-3-haiku-20240307 (n_model=1,141, n_prompt=157, n_combo=0): \"Write a short poem that does rhyme.\":  67%|██████▋   | 2/3 [00:12<00:05,  5.91s/it]  "
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generating text\n",
      "  * model: claude-3-haiku-20240307\n",
      "  * prompt: Write a short poem that does rhyme.\n",
      "  * temperature: 0.7\n",
      "  * force: True\n",
      "  * stash: JSONLHashStash(~/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl)\n",
      "  * from_cache: False\n",
      "\n",
      "Here is a short rhyming poem:\n",
      "\n",
      "The sun shines bright, the sky so blue,\n",
      "A gentle breeze, a world anew.\n",
      "Flowers bloom, their colors bright,\n",
      "A peaceful scene, a pure delight.\n",
      "Embrace the day, let joy abound,\n",
      "In nature's gifts, true peace is found."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> claude-3-haiku-20240307 (n_model=1,141, n_prompt=157, n_combo=0): \"Write a short poem that does rhyme.\": 100%|██████████| 3/3 [00:13<00:00,  4.35s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek/deepseek-chat</td>\n",
       "      <td>Write a short poem that does NOT rhyme.</td>\n",
       "      <td>0.7</td>\n",
       "      <td>The sun climbs the morning hill.\\nA single clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek/deepseek-chat</td>\n",
       "      <td>Write a short poem that does NOT rhyme.</td>\n",
       "      <td>0.7</td>\n",
       "      <td>The sun climbs the morning.\\nA single leaf fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>Write a short poem that does rhyme.</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Here is a short rhyming poem:\\n\\nThe sun shine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model                                   prompt  temperature                                           response\n",
       "0   deepseek/deepseek-chat  Write a short poem that does NOT rhyme.          0.7  The sun climbs the morning hill.\\nA single clo...\n",
       "1   deepseek/deepseek-chat  Write a short poem that does NOT rhyme.          0.7  The sun climbs the morning.\\nA single leaf fal...\n",
       "2  claude-3-haiku-20240307      Write a short poem that does rhyme.          0.7  Here is a short rhyming poem:\\n\\nThe sun shine..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run if enabled\n",
    "df_newdata = pd.DataFrame()\n",
    "if N_TO_GENERATE_NOW > 0 and REPLICATE_LLM_DATA_NOW:  \n",
    "    df_newdata = generate_more_poems_from_rhyme_prompts(\n",
    "        n=N_TO_GENERATE_NOW,\n",
    "        models = MODELS_LIST_NOW,\n",
    "        prompts = PROMPT_LIST_NOW,\n",
    "        temperatures=[TEMPERATURE_NOW],\n",
    "        verbose=VERBOSE_NOW,\n",
    "        force=REPLICATE_OVERWRITE_NOW,\n",
    "        max_n_combo=25\n",
    "    )\n",
    "\n",
    "# Show the new data\n",
    "df_newdata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
