{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting for un/rhyming poems at scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from generative_formalism import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set params\n",
    "MODELS_LIST_NOW = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    # 'claude-3-opus-20240229',\n",
    "    # 'claude-3-sonnet-20240229',\n",
    "    'deepseek/deepseek-chat',\n",
    "    # 'gemini-pro',\n",
    "    # 'gpt-3.5-turbo',\n",
    "    # 'gpt-4-turbo',\n",
    "    # 'ollama/llama3.1:70b',\n",
    "    # 'ollama/llama3.1:8b',\n",
    "    # 'ollama/olmo2',\n",
    "    # 'ollama/olmo2:13b'\n",
    "]\n",
    "\n",
    "PROMPT_LIST_NOW = PROMPT_LIST\n",
    "\n",
    "# PROMPT_LIST_NOW = [\n",
    "#  'Write a poem.',\n",
    "#  'Write a long poem.',\n",
    "#  'Write a short poem.',\n",
    "#  'Write an rhyming poem.',\n",
    "#  'Write an unrhymed poem.',\n",
    "#  'Write a poem in free verse.',\n",
    "#  'Write a poem in blank verse.',\n",
    "#  'Write a poem that does rhyme.',\n",
    "#  'Write a poem (with 20+ lines).',\n",
    "#  'Write a poem in ballad stanzas.',\n",
    "#  'Write a poem in heroic couplets.',\n",
    "#  'Write a poem that does NOT rhyme.',\n",
    "#  'Write a long poem that does rhyme.',\n",
    "#  'Write a short poem that does rhyme.',\n",
    "#  'Write a poem in groups of two lines.',\n",
    "#  'Write a long poem that does NOT rhyme.',\n",
    "#  'Write a short poem that does NOT rhyme.',\n",
    "#  'Write a poem in stanzas of 4 lines each.',\n",
    "#  'Write a poem (with 20+ lines) that rhymes.',\n",
    "#  'Write a poem in the style of Walt Whitman.',\n",
    "#  'Write a poem in the style of Emily Dickinson.',\n",
    "#  'Write a poem (with 20+ lines) that does NOT rhyme.',\n",
    "#  \"Write an ryhmed poem in the style of Shakespeare's sonnets.\"\n",
    "# ]\n",
    "\n",
    "\n",
    "N_TO_GENERATE_NOW = 3\n",
    "\n",
    "VERBOSE_NOW = True\n",
    "\n",
    "TEMPERATURE_NOW = DEFAULT_TEMPERATURE  # 0.7\n",
    "\n",
    "REPLICATE_OVERWRITE_NOW = True\n",
    "\n",
    "REPLICATE_LLM_DATA_NOW = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gemini API key\n",
      "✓ OpenAI API key\n",
      "✓ Anthropic API key\n",
      "✓ DeepSeek API key\n"
     ]
    }
   ],
   "source": [
    "check_api_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`generate_more_poems_from_rhyme_prompts`**\n",
       "\n",
       "```md\n",
       "\n",
       "    Generate more poems from rhyme prompts using various models and configurations.\n",
       "    \n",
       "    This function generates additional poems by sampling from available models and prompts,\n",
       "    with intelligent prioritization of underrepresented combinations to ensure balanced\n",
       "    data collection across different model-prompt pairs.\n",
       "    \n",
       "    Args:\n",
       "        n (int, optional): Number of poems to generate. Defaults to 3.\n",
       "        df_sofar (pd.DataFrame, optional): Existing dataframe of generated poems to build upon.\n",
       "            If None, loads all existing rhyme promptings. Defaults to None.\n",
       "        models (list, optional): List of model identifiers to use for generation.\n",
       "            Defaults to MODEL_LIST from constants.\n",
       "        prompts (list, optional): List of prompt templates to use for generation.\n",
       "            Defaults to PROMPT_LIST from constants.\n",
       "        temperatures (list, optional): List of temperature values for generation.\n",
       "            If None, uses default temperature. Defaults to None.\n",
       "        verbose (bool, optional): Whether to print progress and status information.\n",
       "            Defaults to True.\n",
       "        force (bool, optional): Whether to force regeneration even if cached results exist.\n",
       "            Defaults to False.\n",
       "        max_n_combo (int, optional): Maximum number of entries allowed per model-prompt\n",
       "            combination. If provided, model-prompt pairs that already have this many\n",
       "            or more entries will be excluded from selection. Defaults to None (no limit).\n",
       "    \n",
       "    Returns:\n",
       "        list: List of dictionaries containing generated poem data, including model,\n",
       "            prompt, temperature, generated text, and metadata.\n",
       "    \n",
       "    Note:\n",
       "        The function uses inverse probability weighting to prioritize model-prompt\n",
       "        combinations that have been used less frequently, ensuring balanced sampling\n",
       "        across the available options. Models that consistently fail are temporarily\n",
       "        excluded from further attempts.\n",
       "    \n",
       "```\n",
       "----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generates poems according to least used model-prompt pairs\n",
    "documentation(generate_more_poems_from_rhyme_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Collecting genai rhyme promptings as used in paper\n",
      "  * Collecting from /Users/rj416/github/generative-formalism/data/corpus_genai_promptings.csv.gz\n",
      "  * 17,988 generated responses\n",
      "  * 16,935 unique responses\n",
      "  * 16,871 unique poems\n",
      "  * 23 unique prompts\n",
      "  * 3 unique prompt types\n",
      "\n",
      "* Collecting genai rhyme promptings as replicated here\n",
      "  * Collecting from /Users/rj416/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl\n",
      "  * 292 generated poems\n",
      "  * 291 generated responses\n",
      "  * 262 unique responses\n",
      "  * 262 unique poems\n",
      "  * 23 unique prompts\n",
      "  * 3 unique prompt types\n",
      "  * Filtered out 202 model-prompt combinations with >= 25 entries\n",
      "  * Using 2 models and 4 prompts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> deepseek/deepseek-chat (n_model=680, n_prompt=158, n_combo=9): \"Write a short poem that does rhyme.\":   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generating text\n",
      "  * model: deepseek/deepseek-chat\n",
      "  * prompt: Write a short poem that does rhyme.\n",
      "  * temperature: 0.7\n",
      "  * force: True\n",
      "  * stash: JSONLHashStash(~/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl)\n",
      "  * from_cache: False\n",
      "\n",
      "The sun dips low, the day is done,\n",
      "A painted sky for everyone.\n",
      "The stars peek out, so bold and bright,\n",
      "To guard the secrets of the night."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> deepseek/deepseek-chat (n_model=681, n_prompt=159, n_combo=10): \"Write a short poem that does rhyme.\":  33%|███▎      | 1/3 [00:05<00:10,  5.35s/it]"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generating text\n",
      "  * model: deepseek/deepseek-chat\n",
      "  * prompt: Write a short poem that does rhyme.\n",
      "  * temperature: 0.7\n",
      "  * force: True\n",
      "  * stash: JSONLHashStash(~/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl)\n",
      "  * from_cache: False\n",
      "\n",
      "The sun dips low, the day is done,\n",
      "A painted sky for everyone.\n",
      "The stars peek through with gentle light\n",
      "To guard the quiet, darkening night."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> claude-3-haiku-20240307 (n_model=1,061, n_prompt=160, n_combo=1): \"Write a short poem that does rhyme.\":  67%|██████▋   | 2/3 [00:11<00:05,  5.60s/it]"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Generating text\n",
      "  * model: claude-3-haiku-20240307\n",
      "  * prompt: Write a short poem that does rhyme.\n",
      "  * temperature: 0.7\n",
      "  * force: True\n",
      "  * stash: JSONLHashStash(~/github/generative-formalism/data/stash/genai_rhyme_prompts.jsonl)\n",
      "  * from_cache: False\n",
      "\n",
      "Here is a short rhyming poem:\n",
      "\n",
      "The sun shines bright, the day is clear,\n",
      "A gentle breeze, no need to fear.\n",
      "Birds are singing, flowers bloom,\n",
      "A peaceful scene, no sense of gloom.\n",
      "Nature's beauty all around,\n",
      "Tranquil moments, safe and sound."
     ]
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> claude-3-haiku-20240307 (n_model=1,061, n_prompt=160, n_combo=1): \"Write a short poem that does rhyme.\": 100%|██████████| 3/3 [00:11<00:00,  3.97s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek/deepseek-chat</td>\n",
       "      <td>Write a short poem that does rhyme.</td>\n",
       "      <td>0.7</td>\n",
       "      <td>The sun dips low, the day is done,\\nA painted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek/deepseek-chat</td>\n",
       "      <td>Write a short poem that does rhyme.</td>\n",
       "      <td>0.7</td>\n",
       "      <td>The sun dips low, the day is done,\\nA painted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>Write a short poem that does rhyme.</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Here is a short rhyming poem:\\n\\nThe sun shine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model                               prompt  temperature                                           response\n",
       "0   deepseek/deepseek-chat  Write a short poem that does rhyme.          0.7  The sun dips low, the day is done,\\nA painted ...\n",
       "1   deepseek/deepseek-chat  Write a short poem that does rhyme.          0.7  The sun dips low, the day is done,\\nA painted ...\n",
       "2  claude-3-haiku-20240307  Write a short poem that does rhyme.          0.7  Here is a short rhyming poem:\\n\\nThe sun shine..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run if enabled\n",
    "df_newdata = pd.DataFrame()\n",
    "if N_TO_GENERATE_NOW > 0 and REPLICATE_LLM_DATA_NOW:  \n",
    "    df_newdata = generate_more_poems_from_rhyme_prompts(\n",
    "        n=N_TO_GENERATE_NOW,\n",
    "        models = MODELS_LIST_NOW,\n",
    "        prompts = PROMPT_LIST_NOW,\n",
    "        temperatures=[TEMPERATURE_NOW],\n",
    "        verbose=VERBOSE_NOW,\n",
    "        force=REPLICATE_OVERWRITE_NOW,\n",
    "        max_n_combo=25\n",
    "    )\n",
    "\n",
    "# Show the new data\n",
    "df_newdata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
