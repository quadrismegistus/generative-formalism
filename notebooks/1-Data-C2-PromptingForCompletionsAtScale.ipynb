{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting for completions of poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from generative_formalism import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### System prompt\n",
       "\n",
       "```md\n",
       "The following is the first 5 lines from a poem given in the user prompt, whose true number of lines is stated there.\n",
       "\n",
       "Complete the poem – do this from memory if you know it; if not, imitate its style and theme for the same number of lines as in the original.\n",
       "\n",
       "Return lines in tab-separated form, starting from line 6 up to the stated number of lines:\n",
       "\n",
       "    line#\tline\n",
       "\n",
       "Do not return any other text besides these tab-separated lines.\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_n_lines = FIRST_N_LINES\n",
    "system_prompt = get_rhyme_completion_system_prompt(first_n_lines=first_n_lines)\n",
    "printm(f'#### System prompt\\n\\n```md\\n{system_prompt}\\n```\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### User prompt\n",
       "\n",
       "```md\n",
       "NUMBER OF LINES: 10\n",
       "\n",
       "1\tAnd if I have a soul my soul is green\n",
       "2\tAnd if it sings it doesn't sing to me\n",
       "3\tAnd if it loves it loves externally\n",
       "4\tBoth what it has and what it hasn't seen\n",
       "\n",
       "5\tAnd if it's green it may as well be high\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "poem_eg=\"\"\"\n",
    "And if I have a soul my soul is green\n",
    "And if it sings it doesn't sing to me\n",
    "And if it loves it loves externally\n",
    "Both what it has and what it hasn't seen\n",
    "\n",
    "And if it's green it may as well be high\n",
    "And if ambition doesn't give it height\n",
    "And if it only rises with a fight\n",
    "Against itself and not against the sky\n",
    "\n",
    "If all the force it uses leaves me free\n",
    "This proves it not just definite but right\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "user_prompt = get_rhyme_completion_user_prompt(poem_eg, first_n_lines=first_n_lines)\n",
    "printm(f'#### User prompt\\n\\n```md\\n{user_prompt}\\n```')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`generate_more_completions`**\n",
       "\n",
       "```md\n",
       "\n",
       "    Generate more poem completions using various models and source poems.\n",
       "\n",
       "    This function generates additional poem completions by sampling from available models\n",
       "    and source poems from the Chadwyck corpus, with intelligent prioritization of\n",
       "    underrepresented combinations to ensure balanced data collection across different\n",
       "    model-poem pairs.\n",
       "\n",
       "    Args:\n",
       "        n (int, optional): Number of completions to generate. Defaults to 3.\n",
       "        df_sofar (pd.DataFrame, optional): Existing dataframe of generated completions to build upon.\n",
       "            If None, loads all existing rhyme completions. Defaults to None.\n",
       "        models (list, optional): List of model identifiers to use for generation.\n",
       "            Defaults to MODEL_LIST from constants.\n",
       "        first_n_lines (list, optional): List of possible first_n_lines values to use.\n",
       "            Defaults to [2, 5].\n",
       "        temperatures (list, optional): List of temperature values for generation.\n",
       "            If None, uses default temperature. Defaults to None.\n",
       "        verbose (bool, optional): Whether to print progress and status information.\n",
       "            Defaults to True.\n",
       "        force (bool, optional): Whether to force regeneration even if cached results exist.\n",
       "            Defaults to False.\n",
       "        max_n_combo (int, optional): Maximum number of entries allowed per model-poem\n",
       "            combination. If provided, model-poem pairs that already have this many\n",
       "            or more entries will be excluded from selection. Defaults to None (no limit).\n",
       "        source_poems_sample (str, optional): Which corpus sample to use for source poems.\n",
       "            Options: 'period', 'rhyme', 'period_subcorpus'. Defaults to 'period'.\n",
       "\n",
       "    Returns:\n",
       "        list: List of dictionaries containing generated completion data, including model,\n",
       "            source poem ID, first_n_lines, temperature, and completion results.\n",
       "\n",
       "    Note:\n",
       "        The function uses inverse probability weighting to prioritize model-poem\n",
       "        combinations that have been used less frequently, ensuring balanced sampling\n",
       "        across the available options. Models that consistently fail are temporarily\n",
       "        excluded from further attempts.\n",
       "    \n",
       "```\n",
       "----\n",
       "\n",
       "\n",
       "*Call signature*\n",
       "\n",
       "```md\n",
       "generate_more_completions(\n",
       "    n=3\n",
       "    df_sofar=None\n",
       "    models=[   'claude-3-haiku-20240307',\n",
       "    'claude-3-opus-20240229',\n",
       "    'claude-3-sonnet-20240229',\n",
       "    'deepseek/deepseek-chat',\n",
       "    'gemini-pro',\n",
       "    'gpt-3.5-turbo',\n",
       "    'gpt-4-turbo',\n",
       "    'ollama/llama3.1:70b',\n",
       "    'ollama/llama3.1:8b',\n",
       "    'ollama/olmo2',\n",
       "    'ollama/olmo2:13b']\n",
       "    first_n_lines=5\n",
       "    temperatures=[0.7]\n",
       "    verbose=True\n",
       "    force=True\n",
       "    max_n_combo=None\n",
       "    source_poems_sample='period'\n",
       ")\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documentation(generate_more_completions, signature=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading period sample from /Users/rj416/github/generative-formalism/data/corpus_sample_by_period.replicated.csv.gz\n",
      "* Loading legacy genai rhyme completions from {PATH_REPO}/data/corpus_genai_rhyme_completions.csv.gz\n",
      "* Found 11298 unique human poems for input to models\n",
      "* Found 21130 unique generated poems\n",
      "* Distribution of input poem lengths\n",
      "  6   [ 14 |    36 ]------                                              230\n",
      "* Distribution of output poem lengths\n",
      "  10  -- | 17 ]--                                                     100\n",
      "* Computing line similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 326862/326862 [00:02<00:00, 117089.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Filtered out 169 recognized poems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> gpt-4-turbo (n_model=0, n_poem=0, n_combo=0): poem english/wolcotjo/Z300541100 (first_5): 100%|██████████| 3/3 [00:29<00:00,  9.81s/it]          \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>id_human</th>\n",
       "      <th>first_n_lines</th>\n",
       "      <th>temperature</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94bb2fc2</td>\n",
       "      <td>ollama/llama3.1:8b</td>\n",
       "      <td>english/anderso2/Z300260593</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>id  stanza_num  line_num            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e6968fde</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>american/am0172/Z200149333</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>id  stanza_num  line_num            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59891ca7</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>english/wolcotjo/Z300541100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>id  stanza_num  line_num            ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                   model                     id_human  first_n_lines  temperature                                           response\n",
       "0  94bb2fc2      ollama/llama3.1:8b  english/anderso2/Z300260593              5          0.7            id  stanza_num  line_num            ...\n",
       "1  e6968fde  claude-3-opus-20240229   american/am0172/Z200149333              5          0.7            id  stanza_num  line_num            ...\n",
       "2  59891ca7             gpt-4-turbo  english/wolcotjo/Z300541100              5          0.7            id  stanza_num  line_num            ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'claude-3-opus-20240229',\n",
    "    'claude-3-sonnet-20240229',\n",
    "    'deepseek/deepseek-chat',\n",
    "    'gemini-pro',\n",
    "    'gpt-3.5-turbo',\n",
    "    'gpt-4-turbo',\n",
    "    'ollama/llama3.1:70b',\n",
    "    'ollama/llama3.1:8b',\n",
    "]\n",
    "first_n_lines=FIRST_N_LINES\n",
    "temperatures=[DEFAULT_TEMPERATURE]\n",
    "verbose=False\n",
    "force=False\n",
    "max_n_combo=25\n",
    "source_poems_sample='period'\n",
    "n_to_gen = 3\n",
    "\n",
    "generate_more_completions(\n",
    "    n=n_to_gen,\n",
    "    models=models,\n",
    "    first_n_lines=first_n_lines,\n",
    "    temperatures=temperatures,\n",
    "    verbose=verbose,\n",
    "    force=force,\n",
    "    max_n_combo=max_n_combo,\n",
    "    source_poems_sample=source_poems_sample,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
